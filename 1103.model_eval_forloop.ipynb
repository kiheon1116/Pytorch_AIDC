{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/782 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/kkh/pytorch/1103.model_eval_forloop.ipynb 셀 1\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzetta.skku.edu/home/kkh/pytorch/1103.model_eval_forloop.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m#.cuda(non_blocking=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzetta.skku.edu/home/kkh/pytorch/1103.model_eval_forloop.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m#.cuda(non_blocking=True)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bzetta.skku.edu/home/kkh/pytorch/1103.model_eval_forloop.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m hookF \u001b[39m=\u001b[39m [Hook(name) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39;49m_modules\u001b[39m.\u001b[39;49mmodules())]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzetta.skku.edu/home/kkh/pytorch/1103.model_eval_forloop.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bzetta.skku.edu/home/kkh/pytorch/1103.model_eval_forloop.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'modules'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.nn as nn\n",
    "\n",
    "import hook\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = False\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to('cuda')\n",
    "# model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).to('cuda')\n",
    "# model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).to('cuda')\n",
    "# model = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.IMAGENET1K_V1).to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "mask = [0x80,0xC0,0xE0,0xF0,0xF8,0xFC,0xFE,0xFF]\n",
    "for i in range(7):\n",
    "    model = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.IMAGENET1K_V1)\n",
    "    for name, param in model.named_parameters():\n",
    "        Data_shape = param.shape\n",
    "        \n",
    "        #FP16, FP32\n",
    "        #print(param.view(torch.uint8).view(-1))\n",
    "        \n",
    "        Data_1d = param.view(-1)\n",
    "        Data_1d_int = Data_1d.view(torch.uint8) \n",
    "        Data_1d_int[::2] &= mask[i]                 # \n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "    # dataset = dsets.ImageFolder(\"/media/imagenet/val\", models.ResNet50_Weights.IMAGENET1K_V1.transforms()) ### 2번째 인자, transform\n",
    "    #dataset = dsets.ImageFolder(\"/media/imagenet/val\", models.VGG19_Weights.IMAGENET1K_V1.transforms()) ### 2번째 인자, transform\n",
    "    # dataset = dsets.ImageFolder(\"/media/imagenet/val\", models.MobileNet_V2_Weights.IMAGENET1K_V1.transforms()) ### 2번째 인자, transform\n",
    "    dataset = dsets.ImageFolder(\"/media/imagenet/val\", models.EfficientNet_B2_Weights.IMAGENET1K_V1.transforms()) ### 2번째 인자, transform\n",
    "\n",
    "    loader = DataLoader(dataset= dataset, # dataset\n",
    "                    batch_size=64,   # batch size power to 2\n",
    "                    shuffle = False, # false\n",
    "                    num_workers = 8, # num_workers \n",
    "                    pin_memory=True) # pin_memory \n",
    "\n",
    "    correct = 0\n",
    "    total = 50000\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for input, label in tqdm(loader):\n",
    "        input = input#.cuda(non_blocking=True)\n",
    "        label = label#.cuda(non_blocking=True)\n",
    "        hookF = [Hook(name) for layer in list(model.)]\n",
    "        output = model(input)\n",
    "        pred = torch.argmax(output, 1)\n",
    "        correct += (pred == label).int().sum()\n",
    "    acc1 = correct / total * 100\n",
    "    print(i,'th : ')\n",
    "    print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module : \n",
      "module : conv1\n",
      "module : bn1\n",
      "module : relu\n",
      "module : maxpool\n",
      "module : layer1\n",
      "module : layer1.0\n",
      "module : layer1.0.conv1\n",
      "module : layer1.0.bn1\n",
      "module : layer1.0.conv2\n",
      "module : layer1.0.bn2\n",
      "module : layer1.0.conv3\n",
      "module : layer1.0.bn3\n",
      "module : layer1.0.relu\n",
      "module : layer1.0.downsample\n",
      "module : layer1.0.downsample.0\n",
      "module : layer1.0.downsample.1\n",
      "module : layer1.1\n",
      "module : layer1.1.conv1\n",
      "module : layer1.1.bn1\n",
      "module : layer1.1.conv2\n",
      "module : layer1.1.bn2\n",
      "module : layer1.1.conv3\n",
      "module : layer1.1.bn3\n",
      "module : layer1.1.relu\n",
      "module : layer1.2\n",
      "module : layer1.2.conv1\n",
      "module : layer1.2.bn1\n",
      "module : layer1.2.conv2\n",
      "module : layer1.2.bn2\n",
      "module : layer1.2.conv3\n",
      "module : layer1.2.bn3\n",
      "module : layer1.2.relu\n",
      "module : layer2\n",
      "module : layer2.0\n",
      "module : layer2.0.conv1\n",
      "module : layer2.0.bn1\n",
      "module : layer2.0.conv2\n",
      "module : layer2.0.bn2\n",
      "module : layer2.0.conv3\n",
      "module : layer2.0.bn3\n",
      "module : layer2.0.relu\n",
      "module : layer2.0.downsample\n",
      "module : layer2.0.downsample.0\n",
      "module : layer2.0.downsample.1\n",
      "module : layer2.1\n",
      "module : layer2.1.conv1\n",
      "module : layer2.1.bn1\n",
      "module : layer2.1.conv2\n",
      "module : layer2.1.bn2\n",
      "module : layer2.1.conv3\n",
      "module : layer2.1.bn3\n",
      "module : layer2.1.relu\n",
      "module : layer2.2\n",
      "module : layer2.2.conv1\n",
      "module : layer2.2.bn1\n",
      "module : layer2.2.conv2\n",
      "module : layer2.2.bn2\n",
      "module : layer2.2.conv3\n",
      "module : layer2.2.bn3\n",
      "module : layer2.2.relu\n",
      "module : layer2.3\n",
      "module : layer2.3.conv1\n",
      "module : layer2.3.bn1\n",
      "module : layer2.3.conv2\n",
      "module : layer2.3.bn2\n",
      "module : layer2.3.conv3\n",
      "module : layer2.3.bn3\n",
      "module : layer2.3.relu\n",
      "module : layer3\n",
      "module : layer3.0\n",
      "module : layer3.0.conv1\n",
      "module : layer3.0.bn1\n",
      "module : layer3.0.conv2\n",
      "module : layer3.0.bn2\n",
      "module : layer3.0.conv3\n",
      "module : layer3.0.bn3\n",
      "module : layer3.0.relu\n",
      "module : layer3.0.downsample\n",
      "module : layer3.0.downsample.0\n",
      "module : layer3.0.downsample.1\n",
      "module : layer3.1\n",
      "module : layer3.1.conv1\n",
      "module : layer3.1.bn1\n",
      "module : layer3.1.conv2\n",
      "module : layer3.1.bn2\n",
      "module : layer3.1.conv3\n",
      "module : layer3.1.bn3\n",
      "module : layer3.1.relu\n",
      "module : layer3.2\n",
      "module : layer3.2.conv1\n",
      "module : layer3.2.bn1\n",
      "module : layer3.2.conv2\n",
      "module : layer3.2.bn2\n",
      "module : layer3.2.conv3\n",
      "module : layer3.2.bn3\n",
      "module : layer3.2.relu\n",
      "module : layer3.3\n",
      "module : layer3.3.conv1\n",
      "module : layer3.3.bn1\n",
      "module : layer3.3.conv2\n",
      "module : layer3.3.bn2\n",
      "module : layer3.3.conv3\n",
      "module : layer3.3.bn3\n",
      "module : layer3.3.relu\n",
      "module : layer3.4\n",
      "module : layer3.4.conv1\n",
      "module : layer3.4.bn1\n",
      "module : layer3.4.conv2\n",
      "module : layer3.4.bn2\n",
      "module : layer3.4.conv3\n",
      "module : layer3.4.bn3\n",
      "module : layer3.4.relu\n",
      "module : layer3.5\n",
      "module : layer3.5.conv1\n",
      "module : layer3.5.bn1\n",
      "module : layer3.5.conv2\n",
      "module : layer3.5.bn2\n",
      "module : layer3.5.conv3\n",
      "module : layer3.5.bn3\n",
      "module : layer3.5.relu\n",
      "module : layer4\n",
      "module : layer4.0\n",
      "module : layer4.0.conv1\n",
      "module : layer4.0.bn1\n",
      "module : layer4.0.conv2\n",
      "module : layer4.0.bn2\n",
      "module : layer4.0.conv3\n",
      "module : layer4.0.bn3\n",
      "module : layer4.0.relu\n",
      "module : layer4.0.downsample\n",
      "module : layer4.0.downsample.0\n",
      "module : layer4.0.downsample.1\n",
      "module : layer4.1\n",
      "module : layer4.1.conv1\n",
      "module : layer4.1.bn1\n",
      "module : layer4.1.conv2\n",
      "module : layer4.1.bn2\n",
      "module : layer4.1.conv3\n",
      "module : layer4.1.bn3\n",
      "module : layer4.1.relu\n",
      "module : layer4.2\n",
      "module : layer4.2.conv1\n",
      "module : layer4.2.bn1\n",
      "module : layer4.2.conv2\n",
      "module : layer4.2.bn2\n",
      "module : layer4.2.conv3\n",
      "module : layer4.2.bn3\n",
      "module : layer4.2.relu\n",
      "module : avgpool\n",
      "module : fc\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to('cuda')\n",
    "for name, layer in model.named_modules():\n",
    "     print(f\"module : {name}\")\n",
    "     \n",
    "# for name, child in model.named_children():\n",
    "     # print(f\"name : {name} child : {child}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('1031_kkh': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f584f2a6c3493bc5ad3f9a7fda70fca86566a62a439156976e7315d3ef22a065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
