{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5151/1069155329.py:103: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  result_flag    =    np.zeros((dbx.shape[0],dbx.shape[1]),dtype=np.int)\n",
      "  0%|          | 32/12500 [03:46<24:26:32,  7.06s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch, gc\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, Iterable, Callable\n",
    "from bn_fold import fuse_bn_recursively\n",
    "\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = False\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).to('cuda')\n",
    "model = fuse_bn_recursively(models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1))#.to('cuda'))\n",
    "# model = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.IMAGENET1K_V1).to('cuda')\n",
    "#model = fuse_bn_recursively(models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to('cuda'))\n",
    "def Quant(x : torch.Tensor, n : int) :\n",
    "\n",
    "    N = 2 ** n\n",
    "    N_MIN, N_MAX = -N//2, N//2 - 1\n",
    "    x_max, x_min = torch.max(x) , torch.min(x)\n",
    "\n",
    "    scale = (x_max - x_min) / (N-1)\n",
    "    scale += (x_max * (scale == 0))\n",
    "    zero_n = x_max * N_MIN - x_min * N_MAX\n",
    "    zero_d = x_max - x_min\n",
    "    zero_p =  torch.round(zero_n / (zero_d + 1e-30)) * (zero_d != 0)\n",
    "\n",
    "    x_hat = torch.round(x / scale + zero_p)\n",
    "    x_q   = torch.clip(x_hat, N_MIN, N_MAX).type(torch.int16)\n",
    "\n",
    "    return x_q, scale, zero_p\n",
    "     \n",
    "def DeQuant(    x_q: torch.Tensor, \n",
    "                scale: torch.Tensor, \n",
    "                zero_p: torch.Tensor):\n",
    "    return scale  * (x_q - zero_p)\n",
    "\n",
    "def save_outputs_hook(self, layer_id = str) -> Callable:          \n",
    "    def fn(_, input) :\n",
    "        with torch.no_grad():\n",
    "            Quant_input, scale, zero_p = Quant(input[0],16)\n",
    "            x = Comp(Quant_input)\n",
    "            Comp_output = Decomp(x,Quant_input).reshape(Quant_input.shape)\n",
    "            # print (Quant_input.shape)\n",
    "            # print(Comp_output.shape)\n",
    "            input[0][:] = DeQuant(Comp_output, scale, zero_p).reshape(input[0].shape)\n",
    "            # input[0][:] = DeQuant(Quant_input, scale, zero_p).reshape(input[0].shape)\n",
    "            #input[0][:] = DeQuant(torch.tensor(Comp_output), scale, zero_p).reshape(input[0].shape)\n",
    "            #print(input[0].shape)\n",
    "    return fn\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if (\"layer1\" != name) | (\"layer2\" != name) | (\"layer3\" != name)| (\"layer4\" != name) :\n",
    "        layer = dict([*model.named_modules()])[name]\n",
    "        layer.register_forward_pre_hook(save_outputs_hook(str(name)))\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    Data_shape = param.shape\n",
    "    shape_mul = 1\n",
    "    # numpy_Data_shape = param.detach().cpu().numpy()\n",
    "    for i in Data_shape:\n",
    "        shape_mul *= i\n",
    "    #     print(\"i :\",i, \"shape_mul :\",shape_mul)\n",
    "    # print (\"Data_shape : \",Data_shape, \"shape_mul :\", shape_mul)\n",
    "    # print (\"numpy_Data_shape : \",numpy_Data_shape)\n",
    "    with torch.no_grad():\n",
    "        # print(\"origin : \",param.view(torch.int16).view(-1))\n",
    "        # Quant_input, scale, zero_p = Quant(param,16)\n",
    "        # param[:] = DeQuant(Quant_input, scale, zero_p) \n",
    "        if shape_mul%64 == 0 :\n",
    "            if ('bn' not in name) :\n",
    "                if ('bias' not in name):\n",
    "                    Quant_input, scale, zero_p = Quant(param,16)\n",
    "                    x = Comp(Quant_input)\n",
    "                    Comp_output = Decomp(x, Quant_input).reshape(Quant_input.shape)\n",
    "                    # print(\"not name : \",name, \"x :\",x)\n",
    "                    # print (\"name : \",name,\"Dequant.shape :\",DeQuant(Comp_output, scale, zero_p).shape, \"Data_shape:\",Data_shape)\n",
    "                    param[:] = DeQuant(Comp_output, scale, zero_p)\n",
    "                    # param[:] = DeQuant(Quant_input, scale, zero_p)    \n",
    "                else :\n",
    "                    Quant_input, scale, zero_p = Quant(param,16)\n",
    "                    param[:] = DeQuant(Quant_input, scale, zero_p)                     \n",
    "            else :\n",
    "                Quant_input, scale, zero_p = Quant(param,16)\n",
    "                param[:] = DeQuant(Quant_input, scale, zero_p)    \n",
    "        else:\n",
    "            Quant_input, scale, zero_p = Quant(param,16)\n",
    "            param[:] = DeQuant(Quant_input, scale, zero_p)       \n",
    "             \n",
    "    Data_1d = param.view(-1)\n",
    "    # print(\"Converted : \",Data_1d.view(torch.int16))\n",
    "     \n",
    "dataset = dsets.ImageFolder(\"/media/imagenet/val\", models.MobileNet_V2_Weights.IMAGENET1K_V1.transforms()) ### 2번째 인자, transform\n",
    "loader = DataLoader(dataset= dataset, # dataset\n",
    "                   batch_size=4,   # batch size power to 2\n",
    "                   shuffle = False, # false\n",
    "                   num_workers = 8, # num_workers \n",
    "                   pin_memory=True) # pin_memory \n",
    "\n",
    "correct = 0\n",
    "total = 50000\n",
    "accum = 0\n",
    "model.eval()\n",
    "# torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    for idx, (input, label) in enumerate(tqdm(loader)):\n",
    "        input = input#.cuda(non_blocking=True)\n",
    "        label = label#.cuda(non_blocking=True)     \n",
    "        output = model(input)    \n",
    "        pred = torch.argmax(output, 1)\n",
    "        correct += (pred == label).int().sum()\n",
    "        accum += 32\n",
    "        #if idx % 20 == 0:\n",
    "            #print(idx, correct /accum * 100, correct, accum)\n",
    "    acc1 = correct / total * 100\n",
    "\n",
    "print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "def SR(x_numpy):  # 0000_0000_0111_1111     1111_1111_1000_0000\n",
    "     sr_result = x_numpy\n",
    "     sr_flag = 0\n",
    "     \n",
    "     is_sr_array         = ((x_numpy < 0x80) & (x_numpy >= 0)) | (x_numpy <= -128)\n",
    "     first_element_flag  = ((x_numpy[:,0] < 0x40  & (x_numpy[:,0] >=0)) | (x_numpy[:,0] >= -64)).reshape(-1,1)\n",
    "\n",
    "     row_flag            = (torch.sum(is_sr_array,axis=1) == 64).reshape(-1,1)\n",
    "     sr_flag             = row_flag & first_element_flag\n",
    "     \n",
    "     return sr_flag\n",
    "\n",
    "def ZRLE(x_numpy):\n",
    "     zrle_result = x_numpy \n",
    "     \n",
    "     non_zero_element         = (x_numpy != 0)\n",
    "     non_zero_element_pattern = non_zero_element.view(torch.int32)\n",
    "     \n",
    "     non_zero_size      = (non_zero_element_pattern == 0x00000000) * 6\n",
    "     \n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01000000) * 22\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x00010000) * 21\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x00000100) * 21\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x00000001) * 21\n",
    "     \n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01010000) * 36\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01000100) * 36\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01000001) * 36\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x00010100) * 36\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x00010001) * 36\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x00000101) * 36\n",
    "     \n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01010100) * 52\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01010001) * 52\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01000101) * 52\n",
    "     non_zero_size     += (non_zero_element_pattern == 0x00010101) * 52\n",
    "     \n",
    "     non_zero_size     += (non_zero_element_pattern == 0x01010101) * 66\n",
    "\n",
    "     zrle_flag            = (torch.sum(non_zero_size,axis=1) < 510).reshape(-1,1)\n",
    "\n",
    "     return zrle_flag\n",
    "     \n",
    "     \n",
    "def BPC(x_numpy):\n",
    "     # 1024bit (word * 64)\n",
    "     row  =x_numpy.shape[0]\n",
    "     base_word = x_numpy[:,0].reshape(-1,1)\n",
    "     delta     = x_numpy[:,1:].reshape(-1,) #- base_word ######################################################## must fix\n",
    "     delta_uint8    =    delta.view(np.uint8)\n",
    "     delta_upb      =    np.unpackbits(delta_uint8, bitorder='little')\n",
    "     delta_upb_2d   =    delta_upb.reshape((row,-1,16))[:,:,::-1]\n",
    "     dbp_only       =    np.swapaxes(delta_upb_2d, 1, 2)\n",
    "     dbx            =    dbp_only.copy()\n",
    "     dbx[:,1:,:]    ^=   dbx[:,:15,:]\n",
    "     #print(dbx.shape)     # (2,16,63)\n",
    "     # dbp_only       =     np.array([[[0x0001]*63]*9+[[0x0000]*63]*2+[[0x0001]*63]*5]*2, dtype=np.uint16)                             #2,16,63\n",
    "     # dbx            =     np.array([[[0x0000]*63]*7+[[0x0001]*63]*1+[[0x0000]*63]*1+[[0x0001]*60+[0x0000]*3]*1+[[0x0000]*63]*1+[[0x0001]*2+[0x0000]*61]*3+[[0x0001]+[0x0000]*62]*1+[[0x0001]*32+[0x0000]*31]*1]\n",
    "     #                               +[[[0x0001]*32+[0x0000]*31]*16], dtype=np.uint16) # all case     \n",
    "     dbp_cnt        =    np.sum(dbp_only,axis=2)\n",
    "     dbx_cnt        =    np.sum(dbx,axis=2) ################################################################################ flag0\n",
    "     dbxdbp_flag    =    (dbp_cnt == 0) & (dbx_cnt !=0) ## DBX!=0 ,DBP = 0 ################################################# flag1\n",
    "     dbx_expand     =    np.zeros((dbx.shape[0],dbx.shape[1],dbx.shape[2] + 1), dtype= np.uint8) # 2,16,63+1\n",
    "     dbx_expand[:,:,1:]  =    dbx\n",
    "     dbx_pb         =    np.packbits(dbx_expand.reshape(-1,))\n",
    "     dbx_symbol     =    dbx_pb.view(np.uint64).reshape(2,-1,1)\n",
    "     two_consec     =    dbx_symbol & (dbx_symbol -1)\n",
    "     two_consec_result  =    (dbx_symbol == (two_consec + (two_consec >> 1))) & (dbx_symbol != 0)#.reshape((-1,16)) ############################## flag2\n",
    "     two_consec_flag = two_consec_result.reshape(-1,16)\n",
    "     # 우선순위로 위에서 부터 결과를 구분짓는 flag를 세우려면..\n",
    "     # print(\"dbp : \",dbp_only[0])\n",
    "     # print(\"dbx : \",dbx[0])\n",
    "\n",
    "     ########################## Run length ###############################################\n",
    "     all_zero         =   (dbx_cnt == 0)\n",
    "     all_zero_expand_left  =   np.zeros((dbx.shape[0],dbx.shape[1]), dtype= np.uint8)\n",
    "     all_zero_expand_left[:,1:] = (dbx_cnt[:,:15] == 0)\n",
    "     \n",
    "     all_zero_expand_right  =   np.zeros((dbx.shape[0],dbx.shape[1]), dtype= np.uint8)\n",
    "     all_zero_expand_right[:,:15] = (dbx_cnt[:,1:] == 0)\n",
    "     \n",
    "     # print(all_zero)\n",
    "     # print(all_zero_expand_left)\n",
    "     # print(all_zero_expand_right)\n",
    "     # print((all_zero & all_zero_expand_left)) \n",
    "     case_1         =    (dbx_cnt == 0) & ((all_zero & all_zero_expand_left) == 0) & ((all_zero & all_zero_expand_right) == 0)     # all zero 1\n",
    "     case_0         =    (dbx_cnt == 0) & ~case_1      # all zero 2~16\n",
    "\n",
    "     ###################################################################################\n",
    "     case_2         =    (dbx_cnt == 63)\n",
    "     case_3         =    ~case_2 & (dbxdbp_flag == 1)\n",
    "     case_4         =    ~case_3 & (two_consec_flag == 1)\n",
    "     case_5         =    ~case_3 & ~case_4 & (dbx_cnt == 1)\n",
    "     case_6         =    (~case_0) & (~case_1) & (~case_2) & (~case_3) & (~case_4) & (~case_5)\n",
    "     \n",
    "     result_flag    =    np.zeros((dbx.shape[0],dbx.shape[1]),dtype=np.int)\n",
    "     result_flag    =    (case_0)*0 + (case_1)*3 + (case_2)*5 + (case_3)*6 + (case_4)*11 + (case_5)*12+ (case_6)*64   \n",
    "          \n",
    "     all_zero_2_mask =   np.zeros((dbx.shape[0],dbx.shape[1]+2), dtype= np.uint8)\n",
    "     all_zero_2_mask[:,1:17] = case_0\n",
    "     all_zero_2_mask_left = np.zeros((dbx.shape[0],dbx.shape[1]+2), dtype= np.uint8)\n",
    "     all_zero_2_mask_left[:,1:] = all_zero_2_mask[:,:-1]\n",
    "\n",
    "     all_zero_2_sum = np.sum((all_zero_2_mask ^ all_zero_2_mask_left),axis=1)//2\n",
    "     result_sum     =    np.sum(result_flag, axis=1) + all_zero_2_sum*int(6)\n",
    "     result = (result_sum <= 494)\n",
    "     return result   \n",
    "     \n",
    "\n",
    "def Comp(x : torch.Tensor):      # Tensor (128,3,224,224) -> Tensor (64,3,224,224)\n",
    "    x_numpy = x.reshape(-1,64) # 94080 16\n",
    "#     print(x_numpy.dtype)\n",
    "#     # Do SR\n",
    "    sr_flag = SR(x_numpy)\n",
    "    # Do ZRLE\n",
    "    zrle_flag = ZRLE(x_numpy)\n",
    "    # Do BPC\n",
    "    x = x_numpy.cpu().numpy()\n",
    "    bpc_flag = BPC(x)\n",
    "    bpc_flag = torch.BoolTensor(bpc_flag)\n",
    "\n",
    "\n",
    "    return sr_flag | zrle_flag | bpc_flag.reshape(-1,1)\n",
    "    \n",
    "def Decomp(flag,x_numpy):\n",
    "     x_numpy_reshape = x_numpy.reshape(-1,64)\n",
    "     # print(x_numpy_reshape.shape) # 8, 64\n",
    "     # print(flag.shape)            # 8, 8\n",
    "     return (x_numpy_reshape & 0xff00) + (x_numpy_reshape & 0x00ff)*flag\n",
    "\n",
    "\n",
    "\n",
    "# test_input = np.array([[0,0,0,0x40,  0x30,4,0x30,0x6],\n",
    "#                        [1,0,0,0,     0,0,4,0]])     \n",
    "# ZRLE(test_input)\n",
    "     \n",
    "# x = torch.rand(1,1,1000,64).view(torch.int16)\n",
    "# D = x & 0xff00\n",
    "# # # x = torch.rand(1,3,224,224).view(torch.int16)\n",
    "# # print(\"origin : \",x)\n",
    "# # y = Comp(x)\n",
    "# # print(\"flag: \", y)\n",
    "# # z =Decomp(y,x).reshape(D.shape)\n",
    "# # print(\"z :\",z)\n",
    "# # print(\"sol :\",D)\n",
    "\n",
    "# a = [1, 2, 3, 4] => (4)\n",
    "#     [[1],\n",
    "#      [2],\n",
    "#      [3],\n",
    "#      [4]] => (4,1)\n",
    "\n",
    "# a[0]\n",
    "# flag = Comp(x)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def Quant(x : torch.Tensor, n : int) :\n",
    "\n",
    "    N = 2 ** n\n",
    "    N_MIN, N_MAX = -N//2, N//2 - 1\n",
    "    x_max, x_min = torch.max(x) , torch.min(x)\n",
    "\n",
    "    scale = (x_max - x_min) / (N-1)\n",
    "    scale += (x_max * (scale == 0))\n",
    "    zero_n = x_max * N_MIN - x_min * N_MAX\n",
    "    zero_d = x_max - x_min\n",
    "    zero_p =  torch.round(zero_n / (zero_d + 1e-30)) * (zero_d != 0)\n",
    "\n",
    "    x_hat = torch.round(x / scale + zero_p)\n",
    "    x_q   = torch.clip(x_hat, N_MIN, N_MAX).type(torch.int16)\n",
    "\n",
    "    return x_q, scale, zero_p\n",
    "     \n",
    "     \n",
    "     \n",
    "def DeQuant(   x_q: torch.Tensor, \n",
    "                        scale: torch.Tensor, \n",
    "                        zero_p: torch.Tensor):\n",
    "    return scale  * (x_q - zero_p)\n",
    "\n",
    "\n",
    "x = torch.rand(10,3,224,224)\n",
    "Quant(x,16)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('1031_kkh': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f584f2a6c3493bc5ad3f9a7fda70fca86566a62a439156976e7315d3ef22a065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
